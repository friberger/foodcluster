{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det två Aktivitetstyperna heter \"train\" och \"test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Matfettsblandning havssaltat fett 80% berikad typ Bregott' '5' '711.5'\n",
      "  ..., 'Hård matfettsblandning' '14' 'train']\n",
      " ['Matfettsblandning fett 60 % berikad typ Bregott mellan' '6' '534.2' ...,\n",
      "  'Hård matfettsblandning' '14' 'train']\n",
      " ['Bordsmargarin fett 70% berikad typ Milda' '7' '621.0' ...,\n",
      "  'Hård matfettsblandning' '14' 'train']\n",
      " ..., \n",
      " ['Hälleflundra odlad Atlanten rå' '5926' '112.2' ...,\n",
      "  'Fisk färsk fryst kokt' '6' 'train']\n",
      " ['Torsk odlad rå' '5936' '85.7' ..., 'Fisk färsk fryst kokt' '6' 'train']\n",
      " ['Tortilla wrap' '5974' '313.7' ..., 'Mjukt bröd' '12' 'train']]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('../livs.db')  # Create db and establish connection\n",
    "conn.row_factory = sqlite3.Row\n",
    "curs = conn.cursor()\n",
    "result = []\n",
    "rows = curs.execute('select * from livs where Aktivitetstyp = \"train\" limit 4000')\n",
    "for row in rows:\n",
    "        result.append(row)\n",
    "\n",
    "rows_train = np.array(result)\n",
    "print (rows_train)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 14 14 14 14 14 14 14 14 14  4  4  4 14  4  4  4  4  4  4  4  4  4  4  4\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 18 18\n",
      " 18 18 16 16 16 16 16 16 16  3 16 16  3 16  5  5 16 16 10 18 16 16 16 16 16\n",
      " 18 16 16 16 16 16 18 18  8 10 10  8 10  1  1  1  1  9  1  1  1  1  9  9  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  9  1  1  1  1  8\n",
      "  1  1  9  1  1  9  9  9  1  1  1  1  9  1  1  8  1  9 10 10  1  1  1  1  1\n",
      "  1  8  8  9  9  9  8  8  1  1  1  8  1 10 10  1  8  8  8  8  8  8  1  1  1\n",
      "  4  1 10  1  1  8  8  1  4  8  4  4 10  1  8  8  8  1  1  8 10  8  8 10 10\n",
      " 10 10 10  1  8  1  1 10  1 10 10 10 10  1  4  3 10 10 10  3  3  3 13 13 13\n",
      "  8  8  8 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13  4 19 11  1 11 11 11 11 11 11 11 11 11 11  5 11 11 11 11\n",
      " 11 11 11 11 11 11 11  8 11 11 11  8 19 19 19 10  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9 10  3 10 10  8  8 10 10  9  8  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  3  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  3  3  3  3  3  3  3  3  3\n",
      "  3  3  4  3  3  3  3  3  3 10  3 15  0  3  3  3  3  3  3  3  0  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15  6  6  6  6 10 10 10\n",
      " 19  3  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6\n",
      "  5  6  6  5  6  6  6  6  6  6  6  5  5  6  5  5  5  6  6  5  5  6  5  6  5\n",
      "  6  5  6  5  6  6  5  6  6  5  6  5  6  5  6  5  5  5  6  5  6  5  5  5  5\n",
      "  5  5  5 10  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 10  5  4\n",
      " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      " 17  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  4  4  4  2 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      "  2  2  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  8  4  4\n",
      "  4  3  8 11  8 16  8  4  4  4  8  8 16  3  3  7  3  3  0  0  4 11 11  4 19\n",
      "  4  1 16  4 19 14  2  2  2  4  4  4  4  4  4  4  7  7  7  7  7 14 14 14 14\n",
      "  0  6 14 14 14 14  0  0  3  9  0  0  1  1  5  7  7  0  9  9 12 12 12 12 12\n",
      " 12 12  9  9  9  8  9  9 12  1 14 14 14 14 14 14 14 14 14 14 14  6 18 18 18\n",
      " 18  8  8 18 18 18 18 18 18 18 18 18  6  5  6  5  5  6  6  6  6  5  6 14  1\n",
      "  8  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0 14 14 18  0  3  1  9\n",
      "  1  9  9  9 13 13 13  6  6 12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['711.5', '2977.0', '0.5', ..., '0.0', '0.1', '3.0'],\n",
       "       ['534.2', '2235.3', '0.5', ..., '0.0', '0', '77.0'],\n",
       "       ['621.0', '2598.5', '0.3', ..., '0.0', '0', '35.0'],\n",
       "       ..., \n",
       "       ['112.2', '469.6', '0.0', ..., '30.0', '0.44', '52.0'],\n",
       "       ['85.7', '358.5', '0.0', ..., '30.0', '0.54', '52.0'],\n",
       "       ['313.7', '1312.6', '57.5', ..., '2.0', '0.6', '158.0']],\n",
       "      dtype='<U75')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 16,\n",
    "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38,\n",
    "        40, 41, 42, 43, 44, 45, 46, 47, 48, 50,\n",
    "       51, 52, 53, 54, 55, 56, 57, 59]\n",
    "ndim = len(cols)\n",
    "labels_train = np.array(rows_train.T[61],dtype=int)\n",
    "print (labels_train)\n",
    "#Kolumner med tomma celler: 15, 34, 36, 39, 49, 58, 60\n",
    "#Ta även bort 0 och 1, 61, 62...\n",
    "rows_train = rows_train[:,cols] #Fancy indexing...\n",
    "rows_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncat = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, ndim])\n",
    "W = tf.Variable(tf.zeros([ndim, ncat]))\n",
    "b = tf.Variable(tf.zeros([ncat]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, ncat])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.9).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 14 14 14 14 14 14 14 14 14  4  4  4 14  4  4  4  4  4  4  4  4  4  4  4\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 18 18\n",
      " 18 18 16 16 16 16 16 16 16  3 16 16  3 16  5  5 16 16 10 18 16 16 16 16 16\n",
      " 18 16 16 16 16 16 18 18  8 10 10  8 10  1  1  1  1  9  1  1  1  1  9  9  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  9  1  1  1  1  8\n",
      "  1  1  9  1  1  9  9  9  1  1  1  1  9  1  1  8  1  9 10 10  1  1  1  1  1\n",
      "  1  8  8  9  9  9  8  8  1  1  1  8  1 10 10  1  8  8  8  8  8  8  1  1  1\n",
      "  4  1 10  1  1  8  8  1  4  8  4  4 10  1  8  8  8  1  1  8 10  8  8 10 10\n",
      " 10 10 10  1  8  1  1 10  1 10 10 10 10  1  4  3 10 10 10  3  3  3 13 13 13\n",
      "  8  8  8 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13  4 19 11  1 11 11 11 11 11 11 11 11 11 11  5 11 11 11 11\n",
      " 11 11 11 11 11 11 11  8 11 11 11  8 19 19 19 10  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9 10  3 10 10  8  8 10 10  9  8  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  3  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  3  3  3  3  3  3  3  3  3\n",
      "  3  3  4  3  3  3  3  3  3 10  3 15  0  3  3  3  3  3  3  3  0  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15  6  6  6  6 10 10 10\n",
      " 19  3  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6\n",
      "  5  6  6  5  6  6  6  6  6  6  6  5  5  6  5  5  5  6  6  5  5  6  5  6  5\n",
      "  6  5  6  5  6  6  5  6  6  5  6  5  6  5  6  5  5  5  6  5  6  5  5  5  5\n",
      "  5  5  5 10  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 10  5  4\n",
      " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      " 17  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  4  4  4  2 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      "  2  2  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  8  4  4\n",
      "  4  3  8 11  8 16  8  4  4  4  8  8 16  3  3  7  3  3  0  0  4 11 11  4 19\n",
      "  4  1 16  4 19 14  2  2  2  4  4  4  4  4  4  4  7  7  7  7  7 14 14 14 14\n",
      "  0  6 14 14 14 14  0  0  3  9  0  0  1  1  5  7  7  0  9  9 12 12 12 12 12\n",
      " 12 12  9  9  9  8  9  9 12  1 14 14 14 14 14 14 14 14 14 14 14  6 18 18 18\n",
      " 18  8  8 18 18 18 18 18 18 18 18 18  6  5  6  5  5  6  6  6  6  5  6 14  1\n",
      "  8  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0 14 14 18  0  3  1  9\n",
      "  1  9  9  9 13 13 13  6  6 12]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "n_values = np.max(labels_train) + 1\n",
    "labels_train_one_hot=np.eye(n_values)[labels_train]\n",
    "print(labels_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    sess.run(train_step, feed_dict={x: rows_train, y_: labels_train_one_hot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Majonnäs fett 90%' '21' '784.3' ..., 'Sås dressing majonnäs' '4' 'test']\n",
      " ['Gravlaxsås' '24' '554.9' ..., 'Sås dressing majonnäs' '4' 'test']\n",
      " ['Remouladsås' '25' '707.7' ..., 'Sås dressing majonnäs' '4' 'test']\n",
      " ..., \n",
      " ['Gråärter kokta' '5867' '130.0' ...,\n",
      "  'Baljväxter (bönor, linser och ärter)' '9' 'test']\n",
      " ['Äpple rött typ Ingrid Marie' '5870' '49.3' ..., 'Frukt färsk fryst' '13'\n",
      "  'test']\n",
      " ['Tacosås' '5916' '39.6' ..., 'Sås dressing majonnäs' '4' 'test']]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('../livs.db')  # Create db and establish connection\n",
    "conn.row_factory = sqlite3.Row\n",
    "curs = conn.cursor()\n",
    "result = []\n",
    "rows = curs.execute('select * from livs where Aktivitetstyp = \"test\" limit 4000')\n",
    "for row in rows:\n",
    "        result.append(row)\n",
    "\n",
    "rows_test = np.array(result)\n",
    "print (rows_test)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  4  4 14  4  4  4  4  4 12 12 12 12 12 12 12 18 18 18  3 16 16 16 16 18\n",
      " 16 16 16 16  8 10  8  9  9  1  1  1  1  9  1  1  1  1  1  9  8 10  9  9  8\n",
      "  8 10 10  8  8  8 10  1  1 10  8  3  8 13 13 13 13 13 13 13 11  2 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 10  3  9  9  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  3 10  3  3  3  3  3 10  3\n",
      "  3  3 11  3  0  3 15 15 15 15 15 15 15 15 15 15  6  6  6  6  6  6  5  5  5\n",
      "  5  5  5  5  5 10 17 17 17 17 17 17 17  3  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 19 19 19  2  4  4  4\n",
      "  4  4  4  5 11  8 10  4  8 14  2  4  7 14 14 11  3  5  0  5  9 12 12 12  9\n",
      "  9 14 18 18 18 18  0  5  6  1 15  0 18  1  9 13  4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['784.3', '3281.5', '0.41', ..., '4.76', '0.29', '140.0'],\n",
       "       ['554.9', '2321.9', '13.1', ..., '0.0', '0.1', '18.0'],\n",
       "       ['707.7', '2960.9', '1.07', ..., '4.29', '0.3', '3.0'],\n",
       "       ..., \n",
       "       ['130.0', '543.8', '16.6', ..., '7.8', '1.6', '154.0'],\n",
       "       ['49.3', '206.4', '11.0', ..., '0.0', '0.03', '31.0'],\n",
       "       ['39.6', '165.6', '7.0', ..., '0.0', '0.15', '5.0']],\n",
       "      dtype='<U65')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test = np.array(rows_test.T[61],dtype=int)\n",
    "print (labels_test)\n",
    "#Kolumner med tomma celler: 15, 34, 36, 39, 49, 58, 60\n",
    "#Ta även bort 0 och 1, 61, 62...\n",
    "rows_test = rows_test[:,cols] #Fancy indexing...\n",
    "rows_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 14 14 14 14 14 14 14 14 14  4  4  4 14  4  4  4  4  4  4  4  4  4  4  4\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 18 18\n",
      " 18 18 16 16 16 16 16 16 16  3 16 16  3 16  5  5 16 16 10 18 16 16 16 16 16\n",
      " 18 16 16 16 16 16 18 18  8 10 10  8 10  1  1  1  1  9  1  1  1  1  9  9  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  9  1  1  1  1  8\n",
      "  1  1  9  1  1  9  9  9  1  1  1  1  9  1  1  8  1  9 10 10  1  1  1  1  1\n",
      "  1  8  8  9  9  9  8  8  1  1  1  8  1 10 10  1  8  8  8  8  8  8  1  1  1\n",
      "  4  1 10  1  1  8  8  1  4  8  4  4 10  1  8  8  8  1  1  8 10  8  8 10 10\n",
      " 10 10 10  1  8  1  1 10  1 10 10 10 10  1  4  3 10 10 10  3  3  3 13 13 13\n",
      "  8  8  8 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13  4 19 11  1 11 11 11 11 11 11 11 11 11 11  5 11 11 11 11\n",
      " 11 11 11 11 11 11 11  8 11 11 11  8 19 19 19 10  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9 10  3 10 10  8  8 10 10  9  8  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  3  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  3  3  3  3  3  3  3  3  3\n",
      "  3  3  4  3  3  3  3  3  3 10  3 15  0  3  3  3  3  3  3  3  0  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15  6  6  6  6 10 10 10\n",
      " 19  3  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6\n",
      "  5  6  6  5  6  6  6  6  6  6  6  5  5  6  5  5  5  6  6  5  5  6  5  6  5\n",
      "  6  5  6  5  6  6  5  6  6  5  6  5  6  5  6  5  5  5  6  5  6  5  5  5  5\n",
      "  5  5  5 10  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 10  5  4\n",
      " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      " 17  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  4  4  4  2 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      "  2  2  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  8  4  4\n",
      "  4  3  8 11  8 16  8  4  4  4  8  8 16  3  3  7  3  3  0  0  4 11 11  4 19\n",
      "  4  1 16  4 19 14  2  2  2  4  4  4  4  4  4  4  7  7  7  7  7 14 14 14 14\n",
      "  0  6 14 14 14 14  0  0  3  9  0  0  1  1  5  7  7  0  9  9 12 12 12 12 12\n",
      " 12 12  9  9  9  8  9  9 12  1 14 14 14 14 14 14 14 14 14 14 14  6 18 18 18\n",
      " 18  8  8 18 18 18 18 18 18 18 18 18  6  5  6  5  5  6  6  6  6  5  6 14  1\n",
      "  8  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0 14 14 18  0  3  1  9\n",
      "  1  9  9  9 13 13 13  6  6 12]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "n_values = np.max(labels_test) + 1\n",
    "labels_test_one_hot=np.eye(n_values)[labels_test]\n",
    "print(labels_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.119835\n"
     ]
    }
   ],
   "source": [
    "# Det här måste vara fel...\n",
    "print(sess.run(accuracy, feed_dict={x: rows_test, y_: labels_test_one_hot}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<tf.Tensor 'Placeholder_4:0' shape=(?, 52) dtype=float32>: array([['784.3', '3281.5', '0.41', ..., '4.76', '0.29', '140.0'],\n",
       "        ['554.9', '2321.9', '13.1', ..., '0.0', '0.1', '18.0'],\n",
       "        ['707.7', '2960.9', '1.07', ..., '4.29', '0.3', '3.0'],\n",
       "        ..., \n",
       "        ['130.0', '543.8', '16.6', ..., '7.8', '1.6', '154.0'],\n",
       "        ['49.3', '206.4', '11.0', ..., '0.0', '0.03', '31.0'],\n",
       "        ['39.6', '165.6', '7.0', ..., '0.0', '0.15', '5.0']],\n",
       "       dtype='<U65'),\n",
       " <tf.Tensor 'Placeholder_5:0' shape=(?, 20) dtype=float32>: array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x: rows_test, y_: labels_test_one_hot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
